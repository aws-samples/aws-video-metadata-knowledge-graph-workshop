{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2 - Text and Metadata extraction from the audio of the video file\n",
    "\n",
    "In the follow section of the lab, we're going to:\n",
    "- Transcribe the file's audio into text using Amazon Transcribe\n",
    "- Prepare the transcript data \n",
    "- Run a topic modelling job using Amazon Comprehend to extract topics\n",
    "- Run an NER (Named Entity Recognition) job using Amazon Comprehend to extract names and entities (e.g. countries, places, etc)\n",
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All those metadata will then be used alongside with metadata extracted via computer vision with Rekognition to populate our knowlegegraph in part 3.\n",
    "</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load stored variable from lab0 notebook\n",
    "%store -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jsonlines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transcribe the file's audio into text\n",
    "Amazon Transcribe uses machine learning to recognize speech in audio and video files and transcribe that speech into text. Practical use cases for Amazon Transcribe include transcriptions of customer-agent calls and closed captions for videos.\n",
    "\n",
    "https://docs.aws.amazon.com/transcribe/latest/dg/transcribe-whatis.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import urllib\n",
    "import json\n",
    "import csv\n",
    "import tarfile\n",
    "import pandas as pd\n",
    "import jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcribe = boto3.client('transcribe')\n",
    "\n",
    "transcribe_job_name = \"transcribe_job_knowledge_graph\" + str(random.randint(0, 100000))\n",
    "\n",
    "transcribe_job_uri = \"s3://\" + os.path.join(bucket, s3_video_input_path, video_file)\n",
    "\n",
    "transcription_job = transcribe.start_transcription_job(\n",
    "    TranscriptionJobName=transcribe_job_name,\n",
    "    Media={'MediaFileUri': transcribe_job_uri},\n",
    "    MediaFormat='mp4',\n",
    "    LanguageCode='en-US',\n",
    "    OutputBucketName=bucket\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monitoring the job's completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transcribe_job_knowledge_graph5051\n",
      "...............COMPLETED\n"
     ]
    }
   ],
   "source": [
    "print(transcribe_job_name)\n",
    "while True:\n",
    "    status = transcribe.get_transcription_job(TranscriptionJobName=transcribe_job_name)\n",
    "    if status['TranscriptionJob']['TranscriptionJobStatus'] in ['COMPLETED', 'FAILED']:\n",
    "        break\n",
    "    print(\".\", end='')\n",
    "    time.sleep(5)\n",
    "print(status['TranscriptionJob']['TranscriptionJobStatus'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the transcript file from the s3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.Session().resource('s3')\n",
    "\n",
    "s3_transcript_file_url = status['TranscriptionJob']['Transcript']['TranscriptFileUri']\n",
    "\n",
    "S3_transcript_file_name = s3_transcript_file_url.split('/')[-1]\n",
    "\n",
    "local_transcribe_file_path = os.path.join(tmp_local_folder, S3_transcript_file_name)\n",
    "\n",
    "s3.Bucket(bucket).Object(S3_transcript_file_name).download_file(local_transcribe_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcribe_file = open(local_transcribe_file_path)\n",
    "transcribe_json_data = json.load(transcribe_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the output. below is the itemised version of the transcript, word by word for the 5 first words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'start_time': '0.04',\n",
       "  'end_time': '0.3',\n",
       "  'alternatives': [{'confidence': '0.9671', 'content': \"who's\"}],\n",
       "  'type': 'pronunciation'},\n",
       " {'start_time': '0.3',\n",
       "  'end_time': '0.71',\n",
       "  'alternatives': [{'confidence': '0.9985', 'content': 'excited'}],\n",
       "  'type': 'pronunciation'},\n",
       " {'start_time': '0.71',\n",
       "  'end_time': '0.81',\n",
       "  'alternatives': [{'confidence': '1.0', 'content': 'for'}],\n",
       "  'type': 'pronunciation'},\n",
       " {'start_time': '0.81',\n",
       "  'end_time': '1.88',\n",
       "  'alternatives': [{'confidence': '0.9992', 'content': 'Jamboree'}],\n",
       "  'type': 'pronunciation'},\n",
       " {'alternatives': [{'confidence': '0.0', 'content': ','}],\n",
       "  'type': 'punctuation'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_items = transcribe_json_data['results']['items']\n",
    "transcript_items[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>\n",
    "Loading the file into memory to be used later when building the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formating the transcript to be consumed by Amazon Comprehend for the following 2 jobs.\n",
    "The documentation explains that we can format the input CSV file in 2 ways. Either we provide one document per file or a file containing one document per line. We're going to pick the latter option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have different ways of splitting that text into \"blocks\" of words. One logical way of doing it could be to do it sentence by sentence.</br>\n",
    "We're choosing here to segment our text transcript by chunk of 1 minute.</br>\n",
    "Reason being that later we're going to attach video/audio metadata to 1 minute video segments in order to have a fine grained level information on our video. </br>\n",
    "\n",
    "TODO: implement the cut at a full stop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_size_ms = 60000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function is using the timestamp from each item to break the whole transcript into 1min chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_transcribed_text_for_topic_modelling(transcript_items, segment_size_ms=60000):\n",
    "\n",
    "    #initiatlising current segment with segment size\n",
    "    current_segment_end = segment_size_ms\n",
    "    sentence_list_per_segment = []\n",
    "    buffer_sentence = []\n",
    "    for item in transcript_items:\n",
    "        \n",
    "        #filter on pronunciation, ignoring punctuation for the moment\n",
    "        type_ = item['type']\n",
    "        if type_ == 'pronunciation':\n",
    "            start = float(item['start_time']) * 1000\n",
    "            end = float(item['end_time']) * 1000\n",
    "            content = item['alternatives'][0]['content']\n",
    "            \n",
    "            # splitting text across the different segments\n",
    "            if start <= current_segment_end :\n",
    "                buffer_sentence.append(content)\n",
    "            else:\n",
    "                if (len(buffer_sentence) > 0):\n",
    "                    #appending \"\\r\\n\" at the end of each line - requirement from comprehend\n",
    "                    #buffer_sentence.append(\"\\r\\n\")\n",
    "                    sentence_list_per_segment.append(' '.join(buffer_sentence))\n",
    "                buffer_sentence = []\n",
    "                current_segment_end += segment_size_ms\n",
    "                \n",
    "    #flush the buffer at the end\n",
    "    if (len(buffer_sentence) > 0):\n",
    "        #buffer_sentence.append(\"\\r\\n\")\n",
    "        sentence_list_per_segment.append(' '.join(buffer_sentence))\n",
    "    \n",
    "    return sentence_list_per_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the transcript in the right format\n",
    "\n",
    "video_transcript = prepare_transcribed_text_for_topic_modelling(transcript_items, 60000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now writing the transcript in csv format in S3 to be consumed by Comprehend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video_transcript.csv uploaded to s3://sagemaker-knowledge-graph-ap-southeast-2-327216439222-53755/comprehend-input/video_transcript.csv\n"
     ]
    }
   ],
   "source": [
    "#writing the transcript in csv format in S3 to be consumed by Comprehend\n",
    "def write_list_to_csv(local_file_path, rows, bucket, path):\n",
    "    filename = local_file_path.split('/')[-1]\n",
    "    #create file locally\n",
    "    with open(local_file_path, 'w+') as f:\n",
    "        write = csv.writer(f)\n",
    "        for row in rows:\n",
    "            write.writerow([row])\n",
    "    #upload to S3\n",
    "    boto3.resource('s3').Bucket(bucket).Object(os.path.join(path, filename)).upload_file(local_file_path)\n",
    "    print(f\"{filename} uploaded to s3://{bucket}/{path}/{filename}\")\n",
    "            \n",
    "transcript_filename = 'video_transcript.csv'\n",
    "s3_comprehend_input_path = 'comprehend-input'\n",
    "\n",
    "write_list_to_csv(os.path.join(tmp_local_folder, transcript_filename), \n",
    "                  video_transcript, \n",
    "                  bucket, \n",
    "                  s3_comprehend_input_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're just checking the number of lines in the file we just created which should correspond to the duration of our video in minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines in our file: 5\n"
     ]
    }
   ],
   "source": [
    "num_lines = sum(1 for line in open(os.path.join(tmp_local_folder, transcript_filename)))\n",
    "print(f'Number of lines in our file: {num_lines}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehend - Topic detection\n",
    "We're now ready to launch the first job.\n",
    "\n",
    "You can use Amazon Comprehend to examine the content of a collection of documents to determine common themes. For example, you can give Amazon Comprehend a collection of news articles, and it will determine the subjects, such as sports, politics, or entertainment. The text in the documents doesn't need to be annotated.\n",
    "\n",
    "Amazon Comprehend uses a Latent Dirichlet Allocation-based learning model to determine the topics in a set of documents. It examines each document to determine the context and meaning of a word. The set of words that frequently belong to the same context across the entire document set make up a topic.\n",
    "\n",
    "https://docs.aws.amazon.com/comprehend/latest/dg/topic-modeling.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "comprehend = boto3.client('comprehend')\n",
    "\n",
    "s3_output_data_comprehend = os.path.join(\"s3://\", bucket, 'comprehend-tm-output')\n",
    "s3_input_data_comprehend = os.path.join(\"s3://\", bucket, s3_comprehend_input_path)\n",
    "\n",
    "response = comprehend.start_topics_detection_job(\n",
    "    InputDataConfig={\n",
    "        'S3Uri': s3_input_data_comprehend,\n",
    "        'InputFormat': 'ONE_DOC_PER_LINE'\n",
    "    },\n",
    "    OutputDataConfig={\n",
    "        'S3Uri': s3_output_data_comprehend,\n",
    "    },\n",
    "    DataAccessRoleArn=role_arn,\n",
    "    JobName='comprehend_job_knowledge_graph_' + str(random.randint(0,100000)),\n",
    "    NumberOfTopics=15\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monitoring the progress of the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................................COMPLETED\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    status = comprehend.describe_topics_detection_job(JobId=response['JobId'])\n",
    "    if status['TopicsDetectionJobProperties']['JobStatus']  in ['COMPLETED', 'FAILED']:\n",
    "        break\n",
    "    print(\".\", end='')\n",
    "    time.sleep(10)\n",
    "print(comprehend.describe_topics_detection_job(JobId=response['JobId'])['TopicsDetectionJobProperties']['JobStatus'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After Amazon Comprehend processes your document collection, it returns a compressed archive containing two files, topic-terms.csv and doc-topics.csv. \n",
    "\n",
    "The first output file, topic-terms.csv, is a list of topics in the collection. For each topic, the list includes, by default, the top terms by topic according to their weight. \n",
    "\n",
    "The second file, doc-topics.csv, lists the documents associated with a topic and the proportion of the document that is concerned with the topic. If you specified ONE_DOC_PER_FILE the document is identified by the file name. If you specified ONE_DOC_PER_LINE the document is identified by the file name and the 0-indexed line number within the file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and extract the comprehend topic detection output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to extract a tar file\n",
    "def extract(tar_file, path):\n",
    "    opened_tar = tarfile.open(tar_file)\n",
    "     \n",
    "    if tarfile.is_tarfile(tar_file):\n",
    "        opened_tar.extractall(path)\n",
    "        return path\n",
    "    else:\n",
    "        print(\"The tar file you entered is not a tar file\")\n",
    "\n",
    "#download\n",
    "def download_and_extract_comprehend_job_output(output_s3_uri, dl_path):\n",
    "    s3_bucket = output_s3_uri.split('/')[2]\n",
    "    s3_file_path = '/'.join(output_s3_uri.split('/', 3)[3:])\n",
    "    local_file_path = os.path.join(dl_path, output_s3_uri.split('/')[-1])\n",
    "\n",
    "    boto3.resource('s3').Bucket(s3_bucket).Object(s3_file_path).download_file(local_file_path)\n",
    "    return extract(local_file_path, dl_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_output_s3_uri = comprehend.describe_topics_detection_job(JobId=response['JobId'])['TopicsDetectionJobProperties']['OutputDataConfig']['S3Uri']\n",
    "\n",
    "job_comprehend_output_folder = download_and_extract_comprehend_job_output(topics_output_s3_uri, tmp_local_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking into the 2 output files and loading this into dataframes for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_file = 'doc-topics.csv'\n",
    "topic_terms_file = 'topic-terms.csv'\n",
    "comprehend_topics_df = pd.read_csv(os.path.join(tmp_local_folder, topics_file))\n",
    "comprehend_terms_df = pd.read_csv(os.path.join(tmp_local_folder, topic_terms_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying the 5 first documents and their topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docname</th>\n",
       "      <th>topic</th>\n",
       "      <th>proportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>video_transcript.csv:4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>video_transcript.csv:0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>video_transcript.csv:3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>video_transcript.csv:1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.861177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>video_transcript.csv:1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.138823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  docname  topic  proportion\n",
       "0  video_transcript.csv:4      1    1.000000\n",
       "1  video_transcript.csv:0      2    1.000000\n",
       "2  video_transcript.csv:3      2    1.000000\n",
       "3  video_transcript.csv:1      6    0.861177\n",
       "4  video_transcript.csv:1      3    0.138823"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comprehend_topics_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying top 10 words for topic 1. This will give us an idea of what this topic is about. Remember that topic modelling is not outputing a specific label but instead an unlabeled topic or grouping of documents for which we have a list of prominent words and their weight/importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>term</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>space</td>\n",
       "      <td>0.029340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>great</td>\n",
       "      <td>0.008815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>moe's</td>\n",
       "      <td>0.008815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>show</td>\n",
       "      <td>0.008815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>field</td>\n",
       "      <td>0.008815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>medicine</td>\n",
       "      <td>0.008815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>eye</td>\n",
       "      <td>0.008815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>crucial</td>\n",
       "      <td>0.008815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>today</td>\n",
       "      <td>0.008815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>conversation</td>\n",
       "      <td>0.008815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    topic          term    weight\n",
       "10      1         space  0.029340\n",
       "11      1         great  0.008815\n",
       "12      1         moe's  0.008815\n",
       "13      1          show  0.008815\n",
       "14      1         field  0.008815\n",
       "15      1      medicine  0.008815\n",
       "16      1           eye  0.008815\n",
       "17      1       crucial  0.008815\n",
       "18      1         today  0.008815\n",
       "19      1  conversation  0.008815"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comprehend_terms_df[comprehend_terms_df['topic'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>term</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>6</td>\n",
       "      <td>world</td>\n",
       "      <td>0.052520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>6</td>\n",
       "      <td>science</td>\n",
       "      <td>0.014937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>6</td>\n",
       "      <td>earth</td>\n",
       "      <td>0.014683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>6</td>\n",
       "      <td>woman</td>\n",
       "      <td>0.013489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>6</td>\n",
       "      <td>story</td>\n",
       "      <td>0.012959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>6</td>\n",
       "      <td>action</td>\n",
       "      <td>0.012411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>6</td>\n",
       "      <td>shoot</td>\n",
       "      <td>0.012411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>6</td>\n",
       "      <td>proud</td>\n",
       "      <td>0.012409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>6</td>\n",
       "      <td>today</td>\n",
       "      <td>0.012408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>6</td>\n",
       "      <td>important</td>\n",
       "      <td>0.012408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    topic       term    weight\n",
       "60      6      world  0.052520\n",
       "61      6    science  0.014937\n",
       "62      6      earth  0.014683\n",
       "63      6      woman  0.013489\n",
       "64      6      story  0.012959\n",
       "65      6     action  0.012411\n",
       "66      6      shoot  0.012411\n",
       "67      6      proud  0.012409\n",
       "68      6      today  0.012408\n",
       "69      6  important  0.012408"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comprehend_terms_df[comprehend_terms_df['topic'] == 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprehend NER Named Entity Recognition\n",
    "\n",
    "We're now looking at extracting Named entities from the video's transcript, still using Amazon Comprehend.\n",
    "\n",
    "An entity is a textual reference to the unique name of a real-world object such as people, places, and commercial items, and to precise references to measures such as dates and quantities.\n",
    "\n",
    "https://docs.aws.amazon.com/comprehend/latest/dg/how-entities.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_NER = comprehend.start_entities_detection_job(\n",
    "    InputDataConfig={\n",
    "        'S3Uri': s3_input_data_comprehend,\n",
    "        'InputFormat': 'ONE_DOC_PER_LINE'\n",
    "    },\n",
    "    OutputDataConfig={\n",
    "        'S3Uri': s3_output_data_comprehend,\n",
    "    },\n",
    "    LanguageCode='en',\n",
    "    DataAccessRoleArn=role_arn,\n",
    "    JobName='comprehend_job_knowledge_graph_NER' + str(random.randint(0,100000)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".....................................COMPLETED\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    status_NER = comprehend.describe_entities_detection_job(JobId=response_NER['JobId'])\n",
    "    if status_NER['EntitiesDetectionJobProperties']['JobStatus']  in ['COMPLETED', 'FAILED']:\n",
    "        break\n",
    "    print(\".\", end='')\n",
    "    time.sleep(10)\n",
    "print(comprehend.describe_entities_detection_job(JobId=response_NER['JobId'])['EntitiesDetectionJobProperties']['JobStatus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_output_s3_uri = comprehend.describe_entities_detection_job(JobId=response_NER['JobId'])['EntitiesDetectionJobProperties']['OutputDataConfig']['S3Uri']\n",
    "job_comprehend_output_folder = download_and_extract_comprehend_job_output(ner_output_s3_uri, tmp_local_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look into the output of the NER job. As you can see we've got different types of entities, PERSON, DATE, QUANTITY, LOCATION, ORGANIZATION, OTHERS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_job_data = []\n",
    "with jsonlines.open(os.path.join(tmp_local_folder, 'output')) as ner_json_reader:\n",
    "    for obj in ner_json_reader:\n",
    "        ner_job_data.append(obj['Entities'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'BeginOffset': 18,\n",
       "  'EndOffset': 26,\n",
       "  'Score': 0.8998913437847392,\n",
       "  'Text': 'Jamboree',\n",
       "  'Type': 'EVENT'},\n",
       " {'BeginOffset': 53,\n",
       "  'EndOffset': 62,\n",
       "  'Score': 0.8554136721519294,\n",
       "  'Text': 'this year',\n",
       "  'Type': 'DATE'},\n",
       " {'BeginOffset': 110,\n",
       "  'EndOffset': 112,\n",
       "  'Score': 0.8910259121495451,\n",
       "  'Text': 'dr',\n",
       "  'Type': 'PERSON'},\n",
       " {'BeginOffset': 113,\n",
       "  'EndOffset': 119,\n",
       "  'Score': 0.832157103610494,\n",
       "  'Text': 'Prasad',\n",
       "  'Type': 'PERSON'},\n",
       " {'BeginOffset': 137,\n",
       "  'EndOffset': 141,\n",
       "  'Score': 0.7387116718659316,\n",
       "  'Text': 'Nasa',\n",
       "  'Type': 'ORGANIZATION'},\n",
       " {'BeginOffset': 239,\n",
       "  'EndOffset': 247,\n",
       "  'Score': 0.7160083141368465,\n",
       "  'Text': 'Jamboree',\n",
       "  'Type': 'EVENT'},\n",
       " {'BeginOffset': 314,\n",
       "  'EndOffset': 327,\n",
       "  'Score': 0.8759530140572821,\n",
       "  'Text': 'Mhm Education',\n",
       "  'Type': 'ORGANIZATION'},\n",
       " {'BeginOffset': 456,\n",
       "  'EndOffset': 459,\n",
       "  'Score': 0.9801135950882811,\n",
       "  'Text': 'one',\n",
       "  'Type': 'QUANTITY'},\n",
       " {'BeginOffset': 467,\n",
       "  'EndOffset': 480,\n",
       "  'Score': 0.6408113513652112,\n",
       "  'Text': 'unique things',\n",
       "  'Type': 'QUANTITY'},\n",
       " {'BeginOffset': 555,\n",
       "  'EndOffset': 560,\n",
       "  'Score': 0.8929136869648556,\n",
       "  'Text': '1970s',\n",
       "  'Type': 'DATE'},\n",
       " {'BeginOffset': 621,\n",
       "  'EndOffset': 631,\n",
       "  'Score': 0.9944804997817989,\n",
       "  'Text': 'Carl Sagan',\n",
       "  'Type': 'PERSON'},\n",
       " {'BeginOffset': 662,\n",
       "  'EndOffset': 671,\n",
       "  'Score': 0.9358183081914859,\n",
       "  'Text': 'this year',\n",
       "  'Type': 'DATE'},\n",
       " {'BeginOffset': 690,\n",
       "  'EndOffset': 704,\n",
       "  'Score': 0.9407921449993418,\n",
       "  'Text': 'every 60 years',\n",
       "  'Type': 'QUANTITY'},\n",
       " {'BeginOffset': 709,\n",
       "  'EndOffset': 718,\n",
       "  'Score': 0.9912316387090212,\n",
       "  'Text': 'Christmas',\n",
       "  'Type': 'EVENT'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_job_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'segment_size_ms' (int)\n",
      "Stored 'comprehend_terms_df' (DataFrame)\n",
      "Stored 'comprehend_topics_df' (DataFrame)\n",
      "Stored 'ner_job_data' (list)\n"
     ]
    }
   ],
   "source": [
    "%store segment_size_ms\n",
    "%store comprehend_terms_df\n",
    "%store comprehend_topics_df\n",
    "%store ner_job_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-southeast-2:452832661640:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
